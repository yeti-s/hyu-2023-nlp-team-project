{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkbvJAV-Fm2d",
        "outputId": "8638fa91-0ebf-4ff7-8e2c-cd3d90b60e72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zj4RSOcP8ukV"
      },
      "outputs": [],
      "source": [
        "!pip install torch\n",
        "!pip install transformers==4.30.2\n",
        "!pip install pandas==2.0.3\n",
        "!pip install numpy==1.24.3\n",
        "!pip3 install Cython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxiX1NK-8vJD"
      },
      "outputs": [],
      "source": [
        "# Import models and data\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from torch.optim import Adam\n",
        "import torch.nn.functional as F\n",
        "import data_load"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "주석 처리된 '!git clone https://github.com/hyunmin5366/NLPClassification.git' 부분은 깃허브에서 미니 데이터 셋을 불러오는 부분인데, 전체 데이터 셋은 아래 설명을 따라 다운로드 해주세요.\n",
        "\n",
        "### 데이터 파일 저장하기\n",
        "아래 링크에서 labeeld_data.zip 파일을 다운받아 적절한 위치에 저장한 후 압축을 풀어주세요.\n",
        "  \n",
        "AI Hub의 '낚시성 기사 탐지 데이터'의 라벨링 데이터의 저장되어 있는 구조를 약간 변형하고 서브 디렉토리들의 압축을 풀어 저장해놓은 버전입니다.\n",
        "\n",
        "드라이브 링크: \n",
        "https://drive.google.com/drive/folders/1kC1-GzNGQY-kX5rv0AH1JAtXz4NkyamD?usp=sharing\n",
        "\n",
        "### 데이터 설명\n",
        "\n",
        "labeled_data 디렉토리 안에는 4개의 디렉토리가 있습니다.\n",
        "\n",
        "##### training_set\n",
        "전체 labeled training data를 담은 디렉토리입니다.\n",
        "##### training_set_mini\n",
        "labeled training data 중 2개의 sub directory만 담은 작은 크기의 데이터입니다.\n",
        "##### validation_set\n",
        "전체 labeled validation data를 담은 디렉토리입니다.\n",
        "##### training_set_mini\n",
        "labeled validation data 중 1개의 sub directory만 담은 작은 크기의 데이터입니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJwQamY-_HXK",
        "outputId": "ff489676-9970-452b-f139-8a2b98b12e19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'NLPClassification'...\n",
            "remote: Enumerating objects: 49282, done.\u001b[K\n",
            "remote: Total 49282 (delta 0), reused 0 (delta 0), pack-reused 49282\u001b[K\n",
            "Receiving objects: 100% (49282/49282), 79.63 MiB | 10.48 MiB/s, done.\n",
            "Resolving deltas: 100% (24/24), done.\n",
            "Updating files: 100% (49274/49274), done.\n"
          ]
        }
      ],
      "source": [
        "# github에서 미니 데이터를 불러오는 부분\n",
        "#!git clone https://github.com/hyunmin5366/NLPClassification.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "----\n",
        "### 데이터 불러오기\n",
        "'load_entire_labeled_data' 함수를 통해 데이터를 불러옵니다.\n",
        "\n",
        "##### 첫번째 argument\n",
        "  \n",
        "제가 보내드린 데이터 디렉토리의 경로\n",
        "  \n",
        "(ex. 'training_set_mini', 'training_set', 'validation_set_mini'. 'valication_set'등의 디렉토리)\n",
        "\n",
        "##### 두번째 argument\n",
        "서브 디렉토리(ex. TL_Part1_Clickbait_Auto_EC 등)의 압축을 풀고 로드할 것인지 아닌지를 결정하는 인자.\n",
        "  \n",
        "1: 압축을 풂, 0: 압축을 풀지 않음\n",
        "  \n",
        "제가 미리 압축을 다 풀어놓은 상태이므로, 0으로 놓고 실행해주세요.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Hmyck5j8x6W",
        "outputId": "a6baa30a-c9a8-40fe-beb1-26a332e29b13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] loading labeled data...\n",
            "[INFO] program was done.\n",
            "[INFO] execution time:  189.6964361667633\n",
            "[INFO] loading labeled data...\n",
            "[INFO] program was done.\n",
            "[INFO] execution time:  5.878288269042969\n"
          ]
        }
      ],
      "source": [
        "# 파일의 경로를 적절하게 변형해주세요.\n",
        "# ex) train_df = data_load.load_entire_labeled_data('./labeled_data/training_set', 0)\n",
        "train_df = data_load.load_entire_labeled_data('/content/NLPClassification/training_set_mini', 0)\n",
        "test_df = data_load.load_entire_labeled_data('/content/NLPClassification/validation_set_mini', 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hAAyMtHNCtW8"
      },
      "outputs": [],
      "source": [
        "def prep(train_df):\n",
        "  #수치화\n",
        "  train_df['processLevel'] = train_df['processLevel'].map({'하': 0, '중': 1, '상':2})\n",
        "  train_df['processType'] = train_df['processType'].map({'A': 0, 'D': 1})\n",
        "  train_df['partNum'] = train_df['partNum'].map({'P1':0, 'P2': 1})\n",
        "\n",
        "  #Newtitle, ReferSentenceInfo 제거\n",
        "  train_df = train_df.drop('newTitle', axis=1)\n",
        "  train_df = train_df.drop('referSentenceInfo', axis=1)\n",
        "\n",
        "  #Title, Subtitle, News Content 병합\n",
        "  train_df['newsTitle'] += ': ' + train_df['newsSubTitle']\n",
        "  train_df = train_df.drop('newsSubTitle', axis=1)\n",
        "  train_df['newsText'] = train_df[['newsTitle', 'newsContent']].agg(''.join, axis=1)\n",
        "  return train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kfnbaKod832D"
      },
      "outputs": [],
      "source": [
        "# 2. Preprocessing\n",
        "train_df2 = prep(train_df)\n",
        "test_df2 = prep(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nOoQmNfA9SAS"
      },
      "outputs": [],
      "source": [
        "class TestCBDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.df.iloc[idx, 13]\n",
        "        label = self.df.iloc[idx, 12]\n",
        "        return text, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDUQBB-Q9S4S"
      },
      "outputs": [],
      "source": [
        "CB_train_dataset = TestCBDataset(train_df2)\n",
        "train_loader = DataLoader(CB_train_dataset, batch_size=8, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSf9mSnJFdgj"
      },
      "outputs": [],
      "source": [
        "device_name = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device = torch.device(device_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "model = AutoModelForSequenceClassification.from_pretrained('bert-base-multilingual-cased')\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rket2ivC9WLf"
      },
      "outputs": [],
      "source": [
        "optimizer = Adam(model.parameters(), lr=1e-5)\n",
        "\n",
        "itr = 1\n",
        "p_itr = 100\n",
        "epochs = 1\n",
        "total_loss = 0\n",
        "total_len = 0\n",
        "total_correct = 0\n",
        "\n",
        "\n",
        "model.train()\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    for text, label in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        encoded = tokenizer(text, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
        "        encoded, label = encoded.to(device), label.to(device)\n",
        "        outputs = model(**encoded, labels=label)\n",
        "\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "\n",
        "        pred = torch.argmax(F.softmax(logits), dim=1)\n",
        "        correct = pred.eq(label)\n",
        "        total_correct += correct.sum().item()\n",
        "        total_len += len(label)\n",
        "        total_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if itr % p_itr == 0:\n",
        "            print('[Epoch {}/{}] Iteration {} -> Train Loss: {:.4f}, Accuracy: {:.3f}'.format(epoch+1, epochs, itr, total_loss/p_itr, total_correct/total_len))\n",
        "            total_loss = 0\n",
        "            total_len = 0\n",
        "            total_correct = 0\n",
        "\n",
        "        itr+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cc5ariskN5XR",
        "outputId": "0bb15aac-cf9c-4046-ef86-cb736befd8e4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-11-9b6dbf7e1ed1>:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  pred = torch.argmax(F.softmax(logits), dim=1)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy:  0.8649249583101724\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "\n",
        "CB_eval_dataset = TestCBDataset(test_df2)\n",
        "eval_loader = DataLoader(CB_eval_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "total_loss = 0\n",
        "total_len = 0\n",
        "total_correct = 0\n",
        "\n",
        "for text, label in eval_loader:\n",
        "\n",
        "    encoded = tokenizer(text, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
        "    encoded, label = encoded.to(device), label.to(device)\n",
        "    outputs = model(**encoded, labels=label)\n",
        "\n",
        "    logits = outputs.logits\n",
        "\n",
        "    pred = torch.argmax(F.softmax(logits), dim=1)\n",
        "    correct = pred.eq(label)\n",
        "    total_correct += correct.sum().item()\n",
        "    total_len += len(label)\n",
        "\n",
        "print('Test accuracy: ', total_correct / total_len)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
